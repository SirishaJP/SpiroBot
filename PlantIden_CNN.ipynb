{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Alovera', 'Hibiskus', 'Levender', 'Mint', 'Neem']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.listdir('Medicaldataset'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data visualisation and manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "import seaborn as sns\n",
    " \n",
    "#configure\n",
    "# sets matplotlib to inline and displays graphs below the corressponding cell.\n",
    "%matplotlib inline  \n",
    "style.use('fivethirtyeight')\n",
    "sns.set(style='whitegrid',color_codes=True)\n",
    "\n",
    "#model selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,confusion_matrix,roc_curve,roc_auc_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "#preprocess.\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "#dl libraraies\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam,SGD,Adagrad,Adadelta,RMSprop\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# specifically for cnn\n",
    "from tensorflow.keras.layers import Dropout, Flatten,Activation\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
    " \n",
    "import tensorflow as tf\n",
    "import random as rn\n",
    "\n",
    "# specifically for manipulating zipped images and getting numpy arrays of pixel values of images.\n",
    "import cv2                  \n",
    "import numpy as np  \n",
    "from tqdm import tqdm\n",
    "import os                   \n",
    "from random import shuffle  \n",
    "from zipfile import ZipFile\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=[]\n",
    "Z=[]\n",
    "IMG_SIZE=150\n",
    "Alovera= f'Medicaldataset/Alovera'\n",
    "Hibiskus=f'Medicaldataset/Hibiskus'\n",
    "Levender=f'Medicaldataset/Levender'\n",
    "Mint=f'Medicaldataset/Mint'\n",
    "Neem =f'Medicaldataset/Neem'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_label(img,plant_type):\n",
    "    return plant_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_train_data(plant_type,Medicaldataset):\n",
    "    for img in tqdm(os.listdir(Medicaldataset)):\n",
    "        label=assign_label(img,plant_type)\n",
    "        path = os.path.join(Medicaldataset,img)\n",
    "        img = cv2.imread(path,cv2.IMREAD_COLOR)\n",
    "        img = cv2.resize(img, (IMG_SIZE,IMG_SIZE))\n",
    "        \n",
    "        X.append(np.array(img))\n",
    "        Z.append(str(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 47/47 [00:00<00:00, 323.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "make_train_data('Alovera',Alovera)\n",
    "print(len(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 71/71 [00:00<00:00, 294.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "make_train_data('Hibiskus',Hibiskus)\n",
    "print(len(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 59/59 [00:00<00:00, 458.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "make_train_data('Mint',Mint)\n",
    "print(len(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 41/41 [00:00<00:00, 193.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "make_train_data('Neem',Neem)\n",
    "print(len(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 51/51 [00:00<00:00, 1590.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "make_train_data('Levender',Levender)\n",
    "print(len(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "le=LabelEncoder()\n",
    "Y=le.fit_transform(Z)\n",
    "Y=to_categorical(Y,5)\n",
    "X=np.array(X)\n",
    "X=X/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(X,Y,test_size=0.25,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "rn.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same',activation ='relu', input_shape = (150,150,3)))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "\n",
    "model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same',activation ='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
    "model.add(Conv2D(filters =96, kernel_size = (3,3),padding = 'Same',activation ='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
    "\n",
    "model.add(Conv2D(filters = 96, kernel_size = (3,3),padding = 'Same',activation ='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(5, activation = \"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=24\n",
    "epochs=80\n",
    "\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "red_lr= ReduceLROnPlateau(monitor='val_acc',patience=3,verbose=1,factor=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "     zoom_range = 0.1, # Randomly zoom image \n",
    "        width_shift_range=0.2,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.2,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=True,  # randomly flip images\n",
    "        vertical_flip=False)  # randomly flip images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(learning_rate=0.001),loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 150, 150, 32)      2432      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 75, 75, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 75, 75, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 37, 37, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 37, 37, 96)        55392     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 18, 18, 96)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 18, 18, 96)        83040     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 9, 9, 96)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 7776)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               3981824   \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 2565      \n",
      "=================================================================\n",
      "Total params: 4,143,749\n",
      "Trainable params: 4,143,749\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "8/8 [==============================] - 4s 378ms/step - loss: 1.0391 - accuracy: 0.5593 - val_loss: 1.3077 - val_accuracy: 0.4559\n",
      "Epoch 2/80\n",
      "8/8 [==============================] - 3s 368ms/step - loss: 1.0446 - accuracy: 0.5424 - val_loss: 1.5289 - val_accuracy: 0.3676\n",
      "Epoch 3/80\n",
      "8/8 [==============================] - 3s 372ms/step - loss: 1.0189 - accuracy: 0.5198 - val_loss: 1.3165 - val_accuracy: 0.4706\n",
      "Epoch 4/80\n",
      "8/8 [==============================] - 3s 451ms/step - loss: 1.0013 - accuracy: 0.5537 - val_loss: 1.4987 - val_accuracy: 0.4412\n",
      "Epoch 5/80\n",
      "8/8 [==============================] - 6s 787ms/step - loss: 0.9002 - accuracy: 0.6441 - val_loss: 1.4632 - val_accuracy: 0.4559\n",
      "Epoch 6/80\n",
      "8/8 [==============================] - 6s 681ms/step - loss: 0.8383 - accuracy: 0.6441 - val_loss: 1.5459 - val_accuracy: 0.4412\n",
      "Epoch 7/80\n",
      "8/8 [==============================] - 5s 620ms/step - loss: 0.9328 - accuracy: 0.6328 - val_loss: 1.2348 - val_accuracy: 0.4853\n",
      "Epoch 8/80\n",
      "8/8 [==============================] - 5s 640ms/step - loss: 0.9553 - accuracy: 0.5819 - val_loss: 1.3631 - val_accuracy: 0.4706\n",
      "Epoch 9/80\n",
      "8/8 [==============================] - 5s 626ms/step - loss: 0.8656 - accuracy: 0.6102 - val_loss: 1.5358 - val_accuracy: 0.4559\n",
      "Epoch 10/80\n",
      "8/8 [==============================] - 5s 618ms/step - loss: 0.8616 - accuracy: 0.6441 - val_loss: 1.4883 - val_accuracy: 0.5147\n",
      "Epoch 11/80\n",
      "8/8 [==============================] - 5s 625ms/step - loss: 0.8553 - accuracy: 0.6384 - val_loss: 1.5232 - val_accuracy: 0.5000\n",
      "Epoch 12/80\n",
      "8/8 [==============================] - 5s 662ms/step - loss: 0.8142 - accuracy: 0.6441 - val_loss: 1.7224 - val_accuracy: 0.4706\n",
      "Epoch 13/80\n",
      "8/8 [==============================] - 6s 648ms/step - loss: 0.8641 - accuracy: 0.6328 - val_loss: 1.4812 - val_accuracy: 0.4853\n",
      "Epoch 14/80\n",
      "8/8 [==============================] - 5s 639ms/step - loss: 0.8064 - accuracy: 0.6441 - val_loss: 1.5788 - val_accuracy: 0.4559\n",
      "Epoch 15/80\n",
      "8/8 [==============================] - 6s 684ms/step - loss: 0.8931 - accuracy: 0.6458 - val_loss: 1.4514 - val_accuracy: 0.4853\n",
      "Epoch 16/80\n",
      "8/8 [==============================] - 5s 615ms/step - loss: 0.7832 - accuracy: 0.6610 - val_loss: 1.3829 - val_accuracy: 0.5000\n",
      "Epoch 17/80\n",
      "8/8 [==============================] - 5s 645ms/step - loss: 0.8416 - accuracy: 0.6215 - val_loss: 1.5374 - val_accuracy: 0.4706\n",
      "Epoch 18/80\n",
      "8/8 [==============================] - 5s 601ms/step - loss: 0.7559 - accuracy: 0.6554 - val_loss: 1.4052 - val_accuracy: 0.4853\n",
      "Epoch 19/80\n",
      "8/8 [==============================] - 6s 695ms/step - loss: 0.7773 - accuracy: 0.6615 - val_loss: 1.4198 - val_accuracy: 0.5147\n",
      "Epoch 20/80\n",
      "8/8 [==============================] - 5s 637ms/step - loss: 0.7951 - accuracy: 0.6723 - val_loss: 1.6206 - val_accuracy: 0.4265\n",
      "Epoch 21/80\n",
      "8/8 [==============================] - 5s 664ms/step - loss: 0.7850 - accuracy: 0.6384 - val_loss: 1.4820 - val_accuracy: 0.4706\n",
      "Epoch 22/80\n",
      "8/8 [==============================] - 5s 608ms/step - loss: 0.7540 - accuracy: 0.6780 - val_loss: 1.6406 - val_accuracy: 0.4706\n",
      "Epoch 23/80\n",
      "8/8 [==============================] - 5s 611ms/step - loss: 0.7786 - accuracy: 0.6554 - val_loss: 1.7791 - val_accuracy: 0.4853\n",
      "Epoch 24/80\n",
      "8/8 [==============================] - 5s 650ms/step - loss: 0.8578 - accuracy: 0.6497 - val_loss: 1.4514 - val_accuracy: 0.5000\n",
      "Epoch 25/80\n",
      "8/8 [==============================] - 5s 630ms/step - loss: 0.7715 - accuracy: 0.6723 - val_loss: 1.5133 - val_accuracy: 0.4853\n",
      "Epoch 26/80\n",
      "8/8 [==============================] - 5s 613ms/step - loss: 0.8103 - accuracy: 0.6441 - val_loss: 1.5582 - val_accuracy: 0.3824\n",
      "Epoch 27/80\n",
      "8/8 [==============================] - 5s 657ms/step - loss: 0.8519 - accuracy: 0.6441 - val_loss: 1.3030 - val_accuracy: 0.4412\n",
      "Epoch 28/80\n",
      "8/8 [==============================] - 5s 591ms/step - loss: 0.8242 - accuracy: 0.6497 - val_loss: 1.2469 - val_accuracy: 0.4559\n",
      "Epoch 29/80\n",
      "8/8 [==============================] - 5s 615ms/step - loss: 0.7073 - accuracy: 0.7119 - val_loss: 1.5689 - val_accuracy: 0.4706\n",
      "Epoch 30/80\n",
      "8/8 [==============================] - 5s 675ms/step - loss: 0.7776 - accuracy: 0.6780 - val_loss: 1.6113 - val_accuracy: 0.4853\n",
      "Epoch 31/80\n",
      "8/8 [==============================] - 5s 599ms/step - loss: 0.8028 - accuracy: 0.6497 - val_loss: 1.6556 - val_accuracy: 0.5147\n",
      "Epoch 32/80\n",
      "8/8 [==============================] - 5s 604ms/step - loss: 0.7495 - accuracy: 0.6836 - val_loss: 1.7521 - val_accuracy: 0.4853\n",
      "Epoch 33/80\n",
      "8/8 [==============================] - 5s 656ms/step - loss: 0.7154 - accuracy: 0.6949 - val_loss: 1.5515 - val_accuracy: 0.4853\n",
      "Epoch 34/80\n",
      "8/8 [==============================] - 5s 611ms/step - loss: 0.6716 - accuracy: 0.7006 - val_loss: 1.6552 - val_accuracy: 0.5000\n",
      "Epoch 35/80\n",
      "8/8 [==============================] - 5s 615ms/step - loss: 0.7732 - accuracy: 0.6780 - val_loss: 1.6341 - val_accuracy: 0.5000\n",
      "Epoch 36/80\n",
      "8/8 [==============================] - 5s 631ms/step - loss: 0.7721 - accuracy: 0.6780 - val_loss: 1.8029 - val_accuracy: 0.4706\n",
      "Epoch 37/80\n",
      "8/8 [==============================] - 5s 612ms/step - loss: 0.8914 - accuracy: 0.6667 - val_loss: 1.4636 - val_accuracy: 0.4853\n",
      "Epoch 38/80\n",
      "8/8 [==============================] - 5s 668ms/step - loss: 0.8831 - accuracy: 0.6384 - val_loss: 1.3772 - val_accuracy: 0.5147\n",
      "Epoch 39/80\n",
      "8/8 [==============================] - 5s 641ms/step - loss: 0.9247 - accuracy: 0.5763 - val_loss: 1.4245 - val_accuracy: 0.4559\n",
      "Epoch 40/80\n",
      "8/8 [==============================] - 6s 694ms/step - loss: 0.7264 - accuracy: 0.6780 - val_loss: 1.4931 - val_accuracy: 0.4853\n",
      "Epoch 41/80\n",
      "8/8 [==============================] - 6s 751ms/step - loss: 0.7929 - accuracy: 0.6610 - val_loss: 1.5028 - val_accuracy: 0.5588\n",
      "Epoch 42/80\n",
      "8/8 [==============================] - 7s 940ms/step - loss: 0.7279 - accuracy: 0.7175 - val_loss: 1.6715 - val_accuracy: 0.5000\n",
      "Epoch 43/80\n",
      "8/8 [==============================] - 10s 1s/step - loss: 0.7650 - accuracy: 0.6979 - val_loss: 1.6982 - val_accuracy: 0.5000\n",
      "Epoch 44/80\n",
      "8/8 [==============================] - 8s 898ms/step - loss: 0.7513 - accuracy: 0.6667 - val_loss: 1.6292 - val_accuracy: 0.4706\n",
      "Epoch 45/80\n",
      "8/8 [==============================] - 7s 924ms/step - loss: 0.8737 - accuracy: 0.6094 - val_loss: 1.5943 - val_accuracy: 0.4853\n",
      "Epoch 46/80\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.7706 - accuracy: 0.6667 - val_loss: 1.7216 - val_accuracy: 0.4706\n",
      "Epoch 47/80\n",
      "8/8 [==============================] - 7s 901ms/step - loss: 0.7227 - accuracy: 0.6893 - val_loss: 1.6572 - val_accuracy: 0.4559\n",
      "Epoch 48/80\n",
      "8/8 [==============================] - 7s 905ms/step - loss: 0.7507 - accuracy: 0.6667 - val_loss: 1.5295 - val_accuracy: 0.5735\n",
      "Epoch 49/80\n",
      "8/8 [==============================] - 8s 960ms/step - loss: 0.7000 - accuracy: 0.6875 - val_loss: 1.6061 - val_accuracy: 0.5000\n",
      "Epoch 50/80\n",
      "8/8 [==============================] - 7s 871ms/step - loss: 0.6657 - accuracy: 0.7232 - val_loss: 1.5189 - val_accuracy: 0.5441\n",
      "Epoch 51/80\n",
      "8/8 [==============================] - 7s 989ms/step - loss: 0.7189 - accuracy: 0.7175 - val_loss: 1.5893 - val_accuracy: 0.5588\n",
      "Epoch 52/80\n",
      "8/8 [==============================] - 8s 903ms/step - loss: 0.6553 - accuracy: 0.7119 - val_loss: 1.7168 - val_accuracy: 0.4706\n",
      "Epoch 53/80\n",
      "8/8 [==============================] - 7s 910ms/step - loss: 0.7058 - accuracy: 0.7062 - val_loss: 1.7746 - val_accuracy: 0.5441\n",
      "Epoch 54/80\n",
      "8/8 [==============================] - 8s 929ms/step - loss: 0.7701 - accuracy: 0.6667 - val_loss: 1.7983 - val_accuracy: 0.5588\n",
      "Epoch 55/80\n",
      "8/8 [==============================] - 7s 866ms/step - loss: 0.7927 - accuracy: 0.7119 - val_loss: 1.5929 - val_accuracy: 0.5294\n",
      "Epoch 56/80\n",
      "8/8 [==============================] - 7s 898ms/step - loss: 0.7229 - accuracy: 0.7006 - val_loss: 1.8231 - val_accuracy: 0.4853\n",
      "Epoch 57/80\n",
      "8/8 [==============================] - 7s 953ms/step - loss: 0.7788 - accuracy: 0.6610 - val_loss: 1.6170 - val_accuracy: 0.5000\n",
      "Epoch 58/80\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.7524 - accuracy: 0.6893 - val_loss: 1.7460 - val_accuracy: 0.5588\n",
      "Epoch 59/80\n",
      "8/8 [==============================] - 8s 992ms/step - loss: 0.6600 - accuracy: 0.7458 - val_loss: 1.6434 - val_accuracy: 0.5000\n",
      "Epoch 60/80\n",
      "8/8 [==============================] - 7s 853ms/step - loss: 0.7440 - accuracy: 0.7062 - val_loss: 1.5516 - val_accuracy: 0.5294\n",
      "Epoch 61/80\n",
      "8/8 [==============================] - 7s 881ms/step - loss: 0.6485 - accuracy: 0.7571 - val_loss: 1.3783 - val_accuracy: 0.5294\n",
      "Epoch 62/80\n",
      "8/8 [==============================] - 7s 846ms/step - loss: 0.6928 - accuracy: 0.7119 - val_loss: 1.4684 - val_accuracy: 0.4559\n",
      "Epoch 63/80\n",
      "8/8 [==============================] - 7s 857ms/step - loss: 0.6882 - accuracy: 0.6949 - val_loss: 1.6004 - val_accuracy: 0.5294\n",
      "Epoch 64/80\n",
      "8/8 [==============================] - 8s 924ms/step - loss: 0.6280 - accuracy: 0.7288 - val_loss: 1.6416 - val_accuracy: 0.4412\n",
      "Epoch 65/80\n",
      "8/8 [==============================] - 7s 1s/step - loss: 0.6827 - accuracy: 0.7345 - val_loss: 1.6402 - val_accuracy: 0.5147\n",
      "Epoch 66/80\n",
      "8/8 [==============================] - 7s 922ms/step - loss: 0.6341 - accuracy: 0.7458 - val_loss: 1.6265 - val_accuracy: 0.5441\n",
      "Epoch 67/80\n",
      "8/8 [==============================] - 7s 883ms/step - loss: 0.6455 - accuracy: 0.7345 - val_loss: 1.7472 - val_accuracy: 0.5000\n",
      "Epoch 68/80\n",
      "8/8 [==============================] - 7s 880ms/step - loss: 0.5928 - accuracy: 0.7345 - val_loss: 1.8489 - val_accuracy: 0.5147\n",
      "Epoch 69/80\n",
      "8/8 [==============================] - 6s 746ms/step - loss: 0.6323 - accuracy: 0.7627 - val_loss: 1.5484 - val_accuracy: 0.5735\n",
      "Epoch 70/80\n",
      "8/8 [==============================] - 5s 591ms/step - loss: 0.6358 - accuracy: 0.7232 - val_loss: 1.8257 - val_accuracy: 0.5588\n",
      "Epoch 71/80\n",
      "8/8 [==============================] - 5s 590ms/step - loss: 0.5869 - accuracy: 0.7458 - val_loss: 2.0145 - val_accuracy: 0.4706\n",
      "Epoch 72/80\n",
      "8/8 [==============================] - 6s 692ms/step - loss: 0.6715 - accuracy: 0.7175 - val_loss: 1.9262 - val_accuracy: 0.4706\n",
      "Epoch 73/80\n",
      "8/8 [==============================] - 6s 739ms/step - loss: 0.6180 - accuracy: 0.7514 - val_loss: 1.8352 - val_accuracy: 0.5147\n",
      "Epoch 74/80\n",
      "8/8 [==============================] - 7s 861ms/step - loss: 0.6945 - accuracy: 0.7006 - val_loss: 1.8309 - val_accuracy: 0.4559\n",
      "Epoch 75/80\n",
      "8/8 [==============================] - 10s 1s/step - loss: 0.6731 - accuracy: 0.7401 - val_loss: 1.8036 - val_accuracy: 0.5147\n",
      "Epoch 76/80\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.5845 - accuracy: 0.7627 - val_loss: 1.6913 - val_accuracy: 0.5588\n",
      "Epoch 77/80\n",
      "8/8 [==============================] - 7s 845ms/step - loss: 0.5925 - accuracy: 0.7345 - val_loss: 1.6145 - val_accuracy: 0.5294\n",
      "Epoch 78/80\n",
      "8/8 [==============================] - 7s 855ms/step - loss: 0.5812 - accuracy: 0.7910 - val_loss: 1.8678 - val_accuracy: 0.5441\n",
      "Epoch 79/80\n",
      "8/8 [==============================] - 7s 882ms/step - loss: 0.6281 - accuracy: 0.7345 - val_loss: 2.0869 - val_accuracy: 0.4412\n",
      "Epoch 80/80\n",
      "8/8 [==============================] - 7s 912ms/step - loss: 0.6221 - accuracy: 0.7514 - val_loss: 2.0345 - val_accuracy: 0.5441\n"
     ]
    }
   ],
   "source": [
    "History = model.fit(datagen.flow(x_train,y_train, batch_size=batch_size),\n",
    "                              epochs = epochs, validation_data = (x_test,y_test),\n",
    "                              verbose = 1, steps_per_epoch=x_train.shape[0] // batch_size)\n",
    "# model.fit(x_train,y_train,epochs=epochs,batch_size=batch_size,validation_data = (x_test,y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
